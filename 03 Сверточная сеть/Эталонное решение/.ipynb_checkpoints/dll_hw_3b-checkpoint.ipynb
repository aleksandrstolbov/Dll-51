{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torchvision as tv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import time"
      ],
      "metadata": {
        "id": "toI9_-D9XAfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=256"
      ],
      "metadata": {
        "id": "wyrjNtQ7XOgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SvAJ_PUWOCC"
      },
      "outputs": [],
      "source": [
        "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
        "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZSau92XbzSaS",
        "outputId": "0e31726e-d42c-4c4b-ed4c-946c4942cd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "    nn.Conv2d(1, 20, kernel_size=5, padding=2),\n",
        "    nn.Tanh(),\n",
        "    nn.AvgPool2d(2, stride=2),\n",
        "    nn.Conv2d(20, 50, kernel_size=5, padding=2),\n",
        "    nn.Tanh(),\n",
        "    nn.AvgPool2d(2, stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(2450, 84),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(84, 10)\n",
        ")"
      ],
      "metadata": {
        "id": "gz197p7TXW8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "R4YDGreWyvmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(1, 28, 28), device=device)"
      ],
      "metadata": {
        "id": "3IdU3z4NXZOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8223027-a51f-4636-f682-c186cde29806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 20, 28, 28]             520\n",
            "              Tanh-2           [-1, 20, 28, 28]               0\n",
            "         AvgPool2d-3           [-1, 20, 14, 14]               0\n",
            "            Conv2d-4           [-1, 50, 14, 14]          25,050\n",
            "              Tanh-5           [-1, 50, 14, 14]               0\n",
            "         AvgPool2d-6             [-1, 50, 7, 7]               0\n",
            "           Flatten-7                 [-1, 2450]               0\n",
            "            Linear-8                   [-1, 84]         205,884\n",
            "              Tanh-9                   [-1, 84]               0\n",
            "           Linear-10                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 232,304\n",
            "Trainable params: 232,304\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.46\n",
            "Params size (MB): 0.89\n",
            "Estimated Total Size (MB): 1.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(data_iter, net, device):\n",
        "    acc_sum, n = torch.Tensor([0]).to(device), 0\n",
        "    for X, y in data_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
        "        n += y.shape[0]\n",
        "    return acc_sum.item() / n"
      ],
      "metadata": {
        "id": "DrI5qPMay3jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_iter, test_iter, optimizer, num_epochs, device):\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "\n",
        "        for X, y in train_iter:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.shape[0]\n",
        "\n",
        "        test_acc = evaluate_accuracy(test_iter, net, device)\n",
        "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}' \\\n",
        "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')\n",
        "\n",
        "        if test_acc > 0.9:\n",
        "          break"
      ],
      "metadata": {
        "id": "7doHCpxmXd4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs = 0.001, 20\n",
        "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "train(model, train_iter, test_iter, trainer, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2NiteBMXgwQ",
        "outputId": "5a55b36b-73b0-40bb-8d2e-49b49a035872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.0025, train acc 0.784, test acc 0.828, time 12.4 sec\n",
            "epoch 2, loss 0.0016, train acc 0.855, test acc 0.851, time 12.1 sec\n",
            "epoch 3, loss 0.0014, train acc 0.870, test acc 0.861, time 13.1 sec\n",
            "epoch 4, loss 0.0013, train acc 0.880, test acc 0.871, time 12.3 sec\n",
            "epoch 5, loss 0.0012, train acc 0.888, test acc 0.877, time 12.1 sec\n",
            "epoch 6, loss 0.0012, train acc 0.893, test acc 0.878, time 12.3 sec\n",
            "epoch 7, loss 0.0011, train acc 0.898, test acc 0.878, time 12.3 sec\n",
            "epoch 8, loss 0.0011, train acc 0.902, test acc 0.884, time 12.1 sec\n",
            "epoch 9, loss 0.0010, train acc 0.905, test acc 0.884, time 12.2 sec\n",
            "epoch 10, loss 0.0010, train acc 0.909, test acc 0.886, time 12.4 sec\n",
            "epoch 11, loss 0.0009, train acc 0.912, test acc 0.887, time 12.3 sec\n",
            "epoch 12, loss 0.0009, train acc 0.917, test acc 0.889, time 12.2 sec\n",
            "epoch 13, loss 0.0009, train acc 0.918, test acc 0.890, time 12.1 sec\n",
            "epoch 14, loss 0.0008, train acc 0.922, test acc 0.891, time 12.2 sec\n",
            "epoch 15, loss 0.0008, train acc 0.923, test acc 0.892, time 12.2 sec\n",
            "epoch 16, loss 0.0008, train acc 0.926, test acc 0.894, time 12.7 sec\n",
            "epoch 17, loss 0.0008, train acc 0.928, test acc 0.895, time 12.6 sec\n",
            "epoch 18, loss 0.0007, train acc 0.932, test acc 0.898, time 12.4 sec\n",
            "epoch 19, loss 0.0007, train acc 0.934, test acc 0.896, time 12.1 sec\n",
            "epoch 20, loss 0.0007, train acc 0.936, test acc 0.896, time 12.3 sec\n"
          ]
        }
      ]
    }
  ]
}