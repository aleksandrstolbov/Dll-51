{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0024fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90ee9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eba5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa37a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a200a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82deab8f",
   "metadata": {
    "id": "-UsgWaRFczpO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5593a220",
   "metadata": {
    "id": "Nd6TznshmPZp"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5667c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ef357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6eee95b",
   "metadata": {
    "id": "qb_NW7cVmPZs"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ef7f558",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kw5Kv2i6mPZu",
    "outputId": "abec58e9-6ac4-4622-af32-8d4ddc849f3d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf4ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe150a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d6f310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0][0].numpy().reshape(28,28), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc94700",
   "metadata": {
    "id": "-LcgNXwOmPZ5"
   },
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35e109b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]              60\n",
      "              Tanh-2            [-1, 6, 28, 28]               0\n",
      "         AvgPool2d-3            [-1, 6, 27, 27]               0\n",
      "            Conv2d-4           [-1, 32, 25, 25]           1,760\n",
      "              Tanh-5           [-1, 32, 25, 25]               0\n",
      "         AvgPool2d-6           [-1, 32, 12, 12]               0\n",
      "            Conv2d-7           [-1, 64, 10, 10]          18,496\n",
      "              Tanh-8           [-1, 64, 10, 10]               0\n",
      "         AvgPool2d-9             [-1, 64, 5, 5]               0\n",
      "           Conv2d-10            [-1, 128, 1, 1]         204,928\n",
      "             Tanh-11            [-1, 128, 1, 1]               0\n",
      "          Flatten-12                  [-1, 128]               0\n",
      "           Linear-13                   [-1, 64]           8,256\n",
      "          Dropout-14                   [-1, 64]               0\n",
      "             Tanh-15                   [-1, 64]               0\n",
      "           Linear-16                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 234,150\n",
      "Trainable params: 234,150\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.56\n",
      "Params size (MB): 0.89\n",
      "Estimated Total Size (MB): 1.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(2, stride=1),\n",
    "\n",
    "    nn.Conv2d(6, 32, kernel_size=3),\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(2, stride=2),\n",
    "    \n",
    "    nn.Conv2d(32, 64, kernel_size=3),\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(2, stride=2),\n",
    "    \n",
    "    nn.Conv2d(64, 128, kernel_size=5),\n",
    "    nn.Tanh(),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    \n",
    "    nn.Linear(128, 64),\n",
    "    torch.nn.Dropout(p=0.5), \n",
    "    nn.Tanh(),\n",
    "    \n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f77701",
   "metadata": {},
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=4, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(3, stride=1),\n",
    "    \n",
    "    nn.Conv2d(6, 32, kernel_size=4),\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(2, stride=2),\n",
    "    \n",
    "    \n",
    "    nn.Conv2d(32, 512, kernel_size=4),\n",
    "    nn.Tanh(),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    \n",
    "    nn.Linear(512, 64),\n",
    "    #torch.nn.Dropout(p=0.5), \n",
    "    nn.Tanh(),\n",
    "    \n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505f9b9",
   "metadata": {},
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aa9f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, optimizer, num_epochs, device):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "    \n",
    "        for X, y in train_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    \n",
    "        test_acc = evaluate_accuracy(test_iter, net, device)\n",
    "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}' \\\n",
    "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71bf0546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device):\n",
    "    acc_sum, n = torch.Tensor([0]).to(device), 0\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9341e6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0048, train acc 0.577, test acc 0.691, time 13.8 sec\n",
      "epoch 2, loss 0.0028, train acc 0.735, test acc 0.745, time 13.6 sec\n",
      "epoch 3, loss 0.0024, train acc 0.768, test acc 0.763, time 13.7 sec\n",
      "epoch 4, loss 0.0022, train acc 0.788, test acc 0.785, time 13.7 sec\n",
      "epoch 5, loss 0.0021, train acc 0.806, test acc 0.796, time 13.6 sec\n",
      "epoch 6, loss 0.0020, train acc 0.816, test acc 0.813, time 13.7 sec\n",
      "epoch 7, loss 0.0019, train acc 0.827, test acc 0.810, time 13.7 sec\n",
      "epoch 8, loss 0.0018, train acc 0.834, test acc 0.825, time 13.6 sec\n",
      "epoch 9, loss 0.0017, train acc 0.842, test acc 0.827, time 13.7 sec\n",
      "epoch 10, loss 0.0017, train acc 0.847, test acc 0.841, time 13.7 sec\n",
      "epoch 11, loss 0.0016, train acc 0.852, test acc 0.841, time 13.7 sec\n",
      "epoch 12, loss 0.0016, train acc 0.858, test acc 0.844, time 13.7 sec\n",
      "epoch 13, loss 0.0015, train acc 0.860, test acc 0.841, time 14.1 sec\n",
      "epoch 14, loss 0.0015, train acc 0.864, test acc 0.857, time 13.6 sec\n",
      "epoch 15, loss 0.0015, train acc 0.867, test acc 0.859, time 13.7 sec\n",
      "epoch 16, loss 0.0014, train acc 0.871, test acc 0.858, time 13.8 sec\n",
      "epoch 17, loss 0.0014, train acc 0.873, test acc 0.861, time 13.8 sec\n",
      "epoch 18, loss 0.0014, train acc 0.876, test acc 0.865, time 13.8 sec\n",
      "epoch 19, loss 0.0013, train acc 0.879, test acc 0.860, time 13.7 sec\n",
      "epoch 20, loss 0.0013, train acc 0.882, test acc 0.869, time 13.9 sec\n",
      "epoch 21, loss 0.0013, train acc 0.885, test acc 0.873, time 14.0 sec\n",
      "epoch 22, loss 0.0013, train acc 0.887, test acc 0.870, time 13.7 sec\n",
      "epoch 23, loss 0.0012, train acc 0.888, test acc 0.867, time 13.8 sec\n",
      "epoch 24, loss 0.0012, train acc 0.891, test acc 0.878, time 13.8 sec\n",
      "epoch 25, loss 0.0012, train acc 0.893, test acc 0.875, time 13.8 sec\n",
      "epoch 26, loss 0.0012, train acc 0.895, test acc 0.875, time 13.7 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lr, num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, train_iter, test_iter, optimizer, num_epochs, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      5\u001b[0m     train_l_sum, train_acc_sum, n, start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[0;32m      8\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\.conda\\envs\\Dll-test\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\.conda\\envs\\Dll-test\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Dll-test\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\.conda\\envs\\Dll-test\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\.conda\\envs\\Dll-test\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Dll-test\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Dll-test\\lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.3, 100\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "train(model, train_iter, test_iter, trainer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfd3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913b3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
